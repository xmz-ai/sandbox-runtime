import shellquote from 'shell-quote'
import { logForDebugging } from '../utils/debug.js'
import { randomBytes } from 'node:crypto'
import * as fs from 'fs'
import { spawn, spawnSync } from 'node:child_process'
import type { ChildProcess } from 'node:child_process'
import { tmpdir } from 'node:os'
import path, { join } from 'node:path'
import { ripGrep } from '../utils/ripgrep.js'
import {
  generateProxyEnvVars,
  normalizePathForSandbox,
  RESERVED_ENV_VARS,
  containsGlobChars,
  ensureTmpDir,
} from './sandbox-utils.js'
import type {
  FsReadRestrictionConfig,
  FsWriteRestrictionConfig,
} from './sandbox-schemas.js'
import {
  generateSeccompFilter,
  cleanupSeccompFilter,
  getPreGeneratedBpfPath,
  getApplySeccompBinaryPath,
} from './generate-seccomp-filter.js'

export interface LinuxNetworkBridgeContext {
  httpSocketPath: string
  socksSocketPath: string
  httpBridgeProcess: ChildProcess
  socksBridgeProcess: ChildProcess
  httpProxyPort: number
  socksProxyPort: number
}

export interface LinuxSandboxParams {
  command: string
  needsNetworkRestriction: boolean
  httpSocketPath?: string
  socksSocketPath?: string
  httpProxyPort?: number
  socksProxyPort?: number
  readConfig?: FsReadRestrictionConfig
  writeConfig?: FsWriteRestrictionConfig
  enableWeakerNestedSandbox?: boolean
  allowAllUnixSockets?: boolean
  binShell?: string
  ripgrepConfig?: { command: string; args?: string[] }
  /** Maximum directory depth to search for dangerous files (default: 3) */
  mandatoryDenySearchDepth?: number
  /** Abort signal to cancel the ripgrep scan */
  abortSignal?: AbortSignal
  /** Custom environment variables to set in the sandbox */
  envVars?: Array<{ name: string; value: string }>
  /** Custom temporary directory path */
  tmpDir?: string
  /** Additional NO_PROXY addresses */
  noProxyAddresses?: string[]
}

/** Default max depth for searching dangerous files */
const DEFAULT_MANDATORY_DENY_SEARCH_DEPTH = 3

/**
 * Get mandatory deny paths (Linux only).
 *
 * NOTE: This function previously protected .git/hooks and .git/config automatically.
 * As of the latest changes, all automatic file protection has been removed to give
 * users full control. Users should use denyWrite configuration to protect sensitive
 * files if needed.
 *
 * This function is kept for backward compatibility but now returns an empty array.
 * It may be removed entirely in a future version.
 */
async function linuxGetMandatoryDenyPaths(
  _ripgrepConfig: { command: string; args?: string[] } = { command: 'rg' },
  _maxDepth: number = DEFAULT_MANDATORY_DENY_SEARCH_DEPTH,
  _abortSignal?: AbortSignal,
): Promise<string[]> {
  // All automatic file protection removed - users have full control via denyWrite
  return []
}

/**
 * Expand glob patterns to concrete file paths using ripgrep.
 *
 * IMPORTANT: This only expands to files that exist at the time of expansion.
 * Unlike macOS which uses regex matching in sandbox profiles, Linux's bwrap
 * requires concrete paths for bind mounts. This means:
 * - Files created AFTER expansion will NOT be protected
 * - macOS protects both existing and future files matching the pattern
 *
 * @param patterns Array of paths (can include globs like '**\/*.env')
 * @param ripgrepConfig Ripgrep configuration
 * @param maxDepth Maximum directory depth to search (default: unlimited)
 * @param abortSignal Abort signal for cancellation
 * @returns Array of concrete file paths (globs expanded, literals preserved)
 */
async function expandGlobPatterns(
  patterns: string[],
  ripgrepConfig: { command: string; args?: string[] } = { command: 'rg' },
  maxDepth?: number,
  abortSignal?: AbortSignal,
): Promise<string[]> {
  const cwd = process.cwd()
  const expandedPaths: string[] = []

  for (const pattern of patterns) {
    const normalizedPattern = normalizePathForSandbox(pattern)

    if (containsGlobChars(normalizedPattern)) {
      // Expand glob pattern using ripgrep
      try {
        const ripgrepArgs = [
          '--files',
          '--hidden',
          '-g',
          normalizedPattern,
          '-g',
          '!**/node_modules/**', // Always exclude node_modules
        ]

        // Add max depth if specified
        if (maxDepth !== undefined) {
          ripgrepArgs.push('--max-depth', String(maxDepth))
        }

        const matches = await ripGrep(
          ripgrepArgs,
          cwd,
          abortSignal ?? new AbortController().signal,
          ripgrepConfig,
        )

        // Convert relative paths to absolute
        const absolutePaths = matches.map(m => path.resolve(cwd, m))
        expandedPaths.push(...absolutePaths)

        logForDebugging(
          `[Sandbox Linux] Expanded glob '${pattern}' to ${absolutePaths.length} paths`,
        )
      } catch (error) {
        logForDebugging(
          `[Sandbox Linux] Failed to expand glob '${pattern}': ${error}`,
          { level: 'warn' },
        )
      }
    } else {
      // Literal path - keep as is
      expandedPaths.push(normalizedPattern)
    }
  }

  return expandedPaths
}

// Track generated seccomp filters for cleanup on process exit
const generatedSeccompFilters: Set<string> = new Set()
let exitHandlerRegistered = false

/**
 * Register cleanup handler for generated seccomp filters
 */
function registerSeccompCleanupHandler(): void {
  if (exitHandlerRegistered) {
    return
  }

  process.on('exit', () => {
    for (const filterPath of generatedSeccompFilters) {
      try {
        cleanupSeccompFilter(filterPath)
      } catch {
        // Ignore cleanup errors during exit
      }
    }
  })

  exitHandlerRegistered = true
}

/**
 * Check if Linux sandbox dependencies are available (synchronous)
 * Returns true if bwrap and socat are installed.
 */
export function hasLinuxSandboxDependenciesSync(
  allowAllUnixSockets = false,
): boolean {
  try {
    const bwrapResult = spawnSync('which', ['bwrap'], {
      stdio: 'ignore',
      timeout: 1000,
    })
    const socatResult = spawnSync('which', ['socat'], {
      stdio: 'ignore',
      timeout: 1000,
    })

    const hasBasicDeps = bwrapResult.status === 0 && socatResult.status === 0

    // Check for seccomp dependencies (optional security feature)
    if (!allowAllUnixSockets) {
      // Check if we have a pre-generated BPF filter for this architecture
      const hasPreGeneratedBpf = getPreGeneratedBpfPath() !== null

      // Check if we have the apply-seccomp binary for this architecture
      const hasApplySeccompBinary = getApplySeccompBinaryPath() !== null

      if (!hasPreGeneratedBpf || !hasApplySeccompBinary) {
        // Seccomp not available - log warning but continue with basic sandbox
        // The sandbox will gracefully fall back to allowAllUnixSockets mode
        logForDebugging(
          `[Sandbox Linux] Seccomp filtering not available (missing binaries for ${process.arch}). ` +
            `Sandbox will run without Unix socket blocking (allowAllUnixSockets mode). ` +
            `This is less restrictive but still provides filesystem and network isolation.`,
          { level: 'warn' },
        )
      }
    }

    return hasBasicDeps
  } catch {
    return false
  }
}

/**
 * Initialize the Linux network bridge for sandbox networking
 *
 * ARCHITECTURE NOTE:
 * Linux network sandboxing uses bwrap --unshare-net which creates a completely isolated
 * network namespace with NO network access. To enable network access, we:
 *
 * 1. Host side: Run socat bridges that listen on Unix sockets and forward to host proxy servers
 *    - HTTP bridge: Unix socket -> host HTTP proxy (for HTTP/HTTPS traffic)
 *    - SOCKS bridge: Unix socket -> host SOCKS5 proxy (for SSH/git traffic)
 *
 * 2. Sandbox side: Bind the Unix sockets into the isolated namespace and run socat listeners
 *    - HTTP listener on port 3128 -> HTTP Unix socket -> host HTTP proxy
 *    - SOCKS listener on port 1080 -> SOCKS Unix socket -> host SOCKS5 proxy
 *
 * 3. Configure environment:
 *    - HTTP_PROXY=http://127.0.0.1:3128 for HTTP/HTTPS tools
 *    - GIT_SSH_COMMAND with socat for SSH through SOCKS5
 *
 * LIMITATION: Unlike macOS sandbox which can enforce domain-based allowlists at the kernel level,
 * Linux's --unshare-net provides only all-or-nothing network isolation. Domain filtering happens
 * at the host proxy level, not the sandbox boundary. This means network restrictions on Linux
 * depend on the proxy's filtering capabilities.
 *
 * DEPENDENCIES: Requires bwrap (bubblewrap) and socat
 */
export async function initializeLinuxNetworkBridge(
  httpProxyPort: number,
  socksProxyPort: number,
): Promise<LinuxNetworkBridgeContext> {
  const socketId = randomBytes(8).toString('hex')
  const httpSocketPath = join(tmpdir(), `claude-http-${socketId}.sock`)
  const socksSocketPath = join(tmpdir(), `claude-socks-${socketId}.sock`)

  // Start HTTP bridge
  const httpSocatArgs = [
    `UNIX-LISTEN:${httpSocketPath},fork,reuseaddr`,
    `TCP:127.0.0.1:${httpProxyPort},keepalive,keepidle=10,keepintvl=5,keepcnt=3`,
  ]

  logForDebugging(`Starting HTTP bridge: socat ${httpSocatArgs.join(' ')}`)

  const httpBridgeProcess = spawn('socat', httpSocatArgs, {
    stdio: 'ignore',
  })

  if (!httpBridgeProcess.pid) {
    throw new Error('Failed to start HTTP bridge process')
  }

  // Add error and exit handlers to monitor bridge health
  httpBridgeProcess.on('error', err => {
    logForDebugging(`HTTP bridge process error: ${err}`, { level: 'error' })
  })
  httpBridgeProcess.on('exit', (code, signal) => {
    logForDebugging(
      `HTTP bridge process exited with code ${code}, signal ${signal}`,
      { level: code === 0 ? 'info' : 'error' },
    )
  })

  // Start SOCKS bridge
  const socksSocatArgs = [
    `UNIX-LISTEN:${socksSocketPath},fork,reuseaddr`,
    `TCP:127.0.0.1:${socksProxyPort},keepalive,keepidle=10,keepintvl=5,keepcnt=3`,
  ]

  logForDebugging(`Starting SOCKS bridge: socat ${socksSocatArgs.join(' ')}`)

  const socksBridgeProcess = spawn('socat', socksSocatArgs, {
    stdio: 'ignore',
  })

  if (!socksBridgeProcess.pid) {
    // Clean up HTTP bridge
    if (httpBridgeProcess.pid) {
      try {
        process.kill(httpBridgeProcess.pid, 'SIGTERM')
      } catch {
        // Ignore errors
      }
    }
    throw new Error('Failed to start SOCKS bridge process')
  }

  // Add error and exit handlers to monitor bridge health
  socksBridgeProcess.on('error', err => {
    logForDebugging(`SOCKS bridge process error: ${err}`, { level: 'error' })
  })
  socksBridgeProcess.on('exit', (code, signal) => {
    logForDebugging(
      `SOCKS bridge process exited with code ${code}, signal ${signal}`,
      { level: code === 0 ? 'info' : 'error' },
    )
  })

  // Wait for both sockets to be ready
  const maxAttempts = 5
  for (let i = 0; i < maxAttempts; i++) {
    if (
      !httpBridgeProcess.pid ||
      httpBridgeProcess.killed ||
      !socksBridgeProcess.pid ||
      socksBridgeProcess.killed
    ) {
      throw new Error('Linux bridge process died unexpectedly')
    }

    try {
      // fs already imported
      if (fs.existsSync(httpSocketPath) && fs.existsSync(socksSocketPath)) {
        logForDebugging(`Linux bridges ready after ${i + 1} attempts`)
        break
      }
    } catch (err) {
      logForDebugging(`Error checking sockets (attempt ${i + 1}): ${err}`, {
        level: 'error',
      })
    }

    if (i === maxAttempts - 1) {
      // Clean up both processes
      if (httpBridgeProcess.pid) {
        try {
          process.kill(httpBridgeProcess.pid, 'SIGTERM')
        } catch {
          // Ignore errors
        }
      }
      if (socksBridgeProcess.pid) {
        try {
          process.kill(socksBridgeProcess.pid, 'SIGTERM')
        } catch {
          // Ignore errors
        }
      }
      throw new Error(
        `Failed to create bridge sockets after ${maxAttempts} attempts`,
      )
    }

    await new Promise(resolve => setTimeout(resolve, i * 100))
  }

  return {
    httpSocketPath,
    socksSocketPath,
    httpBridgeProcess,
    socksBridgeProcess,
    httpProxyPort,
    socksProxyPort,
  }
}

/**
 * Build the command that runs inside the sandbox.
 * Sets up HTTP proxy on port 3128 and SOCKS proxy on port 1080
 */
function buildSandboxCommand(
  httpSocketPath: string,
  socksSocketPath: string,
  userCommand: string,
  seccompFilterPath: string | undefined,
  shell?: string,
): string {
  // Default to bash for backward compatibility
  const shellPath = shell || 'bash'
  const socatCommands = [
    `socat TCP-LISTEN:3128,fork,reuseaddr UNIX-CONNECT:${httpSocketPath} >/dev/null 2>&1 &`,
    `socat TCP-LISTEN:1080,fork,reuseaddr UNIX-CONNECT:${socksSocketPath} >/dev/null 2>&1 &`,
    'trap "kill %1 %2 2>/dev/null; exit" EXIT',
  ]

  // If seccomp filter is provided, use apply-seccomp to apply it
  if (seccompFilterPath) {
    // apply-seccomp approach:
    // 1. Outer bwrap/bash: starts socat processes (can use Unix sockets)
    // 2. apply-seccomp: applies seccomp filter and execs user command
    // 3. User command runs with seccomp active (Unix sockets blocked)
    //
    // apply-seccomp is a simple C program that:
    // - Sets PR_SET_NO_NEW_PRIVS
    // - Applies the seccomp BPF filter via prctl(PR_SET_SECCOMP)
    // - Execs the user command
    //
    // This is simpler and more portable than nested bwrap, with no FD redirects needed.
    const applySeccompBinary = getApplySeccompBinaryPath()
    if (!applySeccompBinary) {
      throw new Error(
        'apply-seccomp binary not found. This should have been caught earlier. ' +
          'Ensure vendor/seccomp/{x64,arm64}/apply-seccomp binaries are included in the package.',
      )
    }

    const applySeccompCmd = shellquote.quote([
      applySeccompBinary,
      seccompFilterPath,
      shellPath,
      '-c',
      userCommand,
    ])

    const innerScript = [...socatCommands, applySeccompCmd].join('\n')
    return `${shellPath} -c ${shellquote.quote([innerScript])}`
  } else {
    // No seccomp filter - run user command directly
    const innerScript = [
      ...socatCommands,
      `eval ${shellquote.quote([userCommand])}`,
    ].join('\n')

    return `${shellPath} -c ${shellquote.quote([innerScript])}`
  }
}

/**
 * Generate filesystem args for deny-only read mode
 */
async function generateDenyOnlyFilesystemArgs(
  denyPaths: string[],
  writeConfig: FsWriteRestrictionConfig | undefined,
  ripgrepConfig: { command: string; args?: string[] } = { command: 'rg' },
  mandatoryDenySearchDepth: number = DEFAULT_MANDATORY_DENY_SEARCH_DEPTH,
  abortSignal?: AbortSignal,
): Promise<string[]> {
  const args: string[] = []

  // Determine initial root mount based on write restrictions
  if (writeConfig) {
    // Write restrictions: Start with read-only root, then allow writes to specific paths
    args.push('--ro-bind', '/', '/')

    // Collect normalized allowed write paths for later checking
    const allowedWritePaths: string[] = []

    // Expand globs in allowWrite paths
    const expandedAllowWrite = await expandGlobPatterns(
      writeConfig.allowOnly || [],
      ripgrepConfig,
      mandatoryDenySearchDepth,
      abortSignal,
    )

    // Allow writes to specific paths
    for (const pathPattern of expandedAllowWrite) {
      const normalizedPath = normalizePathForSandbox(pathPattern)

      logForDebugging(
        `[Sandbox Linux] Processing write path: ${pathPattern} -> ${normalizedPath}`,
      )

      // Skip /dev/* paths since --dev /dev already handles them
      if (normalizedPath.startsWith('/dev/')) {
        logForDebugging(`[Sandbox Linux] Skipping /dev path: ${normalizedPath}`)
        continue
      }

      if (!fs.existsSync(normalizedPath)) {
        logForDebugging(
          `[Sandbox Linux] Skipping non-existent write path: ${normalizedPath}`,
        )
        continue
      }

      args.push('--bind', normalizedPath, normalizedPath)
      allowedWritePaths.push(normalizedPath)
    }

    // Deny writes within allowed paths (user-specified + mandatory denies)
    const denyWithinAllowPatterns = [
      ...(writeConfig.denyWithinAllow || []),
      ...(await linuxGetMandatoryDenyPaths(
        ripgrepConfig,
        mandatoryDenySearchDepth,
        abortSignal,
      )),
    ]

    // Expand globs in denyWithinAllow paths
    const expandedDenyWrite = await expandGlobPatterns(
      denyWithinAllowPatterns,
      ripgrepConfig,
      mandatoryDenySearchDepth,
      abortSignal,
    )

    for (const pathPattern of expandedDenyWrite) {
      const normalizedPath = normalizePathForSandbox(pathPattern)

      // Skip /dev/* paths since --dev /dev already handles them
      if (normalizedPath.startsWith('/dev/')) {
        continue
      }

      // Skip non-existent paths
      if (!fs.existsSync(normalizedPath)) {
        logForDebugging(
          `[Sandbox Linux] Skipping non-existent deny path: ${normalizedPath}`,
        )
        continue
      }

      // Only add deny binding if this path is within an allowed write path
      // Otherwise it's already read-only from the initial --ro-bind / /
      const isWithinAllowedPath = allowedWritePaths.some(
        allowedPath =>
          normalizedPath.startsWith(allowedPath + '/') ||
          normalizedPath === allowedPath,
      )

      if (isWithinAllowedPath) {
        args.push('--ro-bind', normalizedPath, normalizedPath)
      } else {
        logForDebugging(
          `[Sandbox Linux] Skipping deny path not within allowed paths: ${normalizedPath}`,
        )
      }
    }
  } else {
    // No write restrictions: Allow all writes
    args.push('--bind', '/', '/')
  }

  // Handle read restrictions by mounting tmpfs over denied paths
  const readDenyPatterns = [...denyPaths]

  // Always hide /etc/ssh/ssh_config.d to avoid permission issues with OrbStack
  // SSH is very strict about config file permissions and ownership, and they can
  // appear wrong inside the sandbox causing "Bad owner or permissions" errors
  if (fs.existsSync('/etc/ssh/ssh_config.d')) {
    readDenyPatterns.push('/etc/ssh/ssh_config.d')
  }

  // Expand globs in read deny paths
  const expandedReadDeny = await expandGlobPatterns(
    readDenyPatterns,
    ripgrepConfig,
    mandatoryDenySearchDepth,
    abortSignal,
  )

  for (const pathPattern of expandedReadDeny) {
    const normalizedPath = normalizePathForSandbox(pathPattern)
    if (!fs.existsSync(normalizedPath)) {
      logForDebugging(
        `[Sandbox Linux] Skipping non-existent read deny path: ${normalizedPath}`,
      )
      continue
    }

    const readDenyStat = fs.statSync(normalizedPath)
    if (readDenyStat.isDirectory()) {
      args.push('--tmpfs', normalizedPath)
    } else {
      // For files, bind /dev/null instead of tmpfs
      args.push('--ro-bind', '/dev/null', normalizedPath)
    }
  }

  return args
}

/**
 * Generate filesystem args for allow-only read mode
 */
async function generateAllowOnlyFilesystemArgs(
  allowPaths: string[],
  denyWithinAllow: string[],
  writeConfig: FsWriteRestrictionConfig | undefined,
  seccompFilterPath?: string,
  ripgrepConfig: { command: string; args?: string[] } = { command: 'rg' },
  mandatoryDenySearchDepth: number = DEFAULT_MANDATORY_DENY_SEARCH_DEPTH,
  abortSignal?: AbortSignal,
): Promise<string[]> {
  const args: string[] = []

  // Allow-only read mode: bwrap creates an empty root by default (no --tmpfs needed)
  // We will selectively bind only allowed read paths later
  // Create standard Linux filesystem symlinks (required for commands to work)
  // Modern Linux systems have /bin -> /usr/bin, /lib -> /usr/lib, etc.
  args.push('--symlink', 'usr/bin', '/bin')
  args.push('--symlink', 'usr/sbin', '/sbin')
  args.push('--symlink', 'usr/lib', '/lib')

  // Only create lib64 symlink if host system has it
  if (fs.existsSync('/usr/lib64')) {
    args.push('--symlink', 'usr/lib64', '/lib64')
  }

  logForDebugging(
    `[Sandbox Linux] Using allow-only read mode with selective bind mounts`,
  )

  // === BIND ALLOWED READ PATHS ===
  // We selectively bind ONLY the allowed paths - nothing else is accessible

  // Special: If seccomp filter is being used, we need to bind the directories
  // containing apply-seccomp binary and BPF filter so they're accessible in the sandbox
  if (seccompFilterPath) {
    const applySeccompBinary = getApplySeccompBinaryPath()
    if (applySeccompBinary) {
      // Get the directory containing apply-seccomp (e.g., /path/to/vendor/seccomp/arm64)
      const applySeccompDir = path.dirname(applySeccompBinary)
      if (fs.existsSync(applySeccompDir)) {
        args.push('--ro-bind', applySeccompDir, applySeccompDir)
        logForDebugging(
          `[Sandbox Linux] Bound seccomp binary directory: ${applySeccompDir}`,
        )
      }
    }

    // Also bind the BPF filter directory if different
    const filterDir = path.dirname(seccompFilterPath)
    if (fs.existsSync(filterDir)) {
      args.push('--ro-bind', filterDir, filterDir)
      logForDebugging(
        `[Sandbox Linux] Bound seccomp filter directory: ${filterDir}`,
      )
    }
  }

  // Step 1: Bind allowed read paths
  // These are the ONLY paths that will be readable in the sandbox
  // Expand globs in allowRead paths
  const expandedAllowRead = await expandGlobPatterns(
    allowPaths,
    ripgrepConfig,
    mandatoryDenySearchDepth,
    abortSignal,
  )

  for (const pathPattern of expandedAllowRead) {
    const normalizedPath = normalizePathForSandbox(pathPattern)

    if (!fs.existsSync(normalizedPath)) {
      logForDebugging(
        `[Sandbox Linux] Skipping non-existent read allow path: ${normalizedPath}`,
      )
      continue
    }

    // Check if this path should also be writable
    const isWritable =
      writeConfig?.allowOnly?.some(
        writePath =>
          normalizePathForSandbox(writePath) === normalizedPath ||
          normalizedPath.startsWith(normalizePathForSandbox(writePath) + '/'),
      ) || false

    if (isWritable) {
      args.push('--bind', normalizedPath, normalizedPath)
    } else {
      args.push('--ro-bind', normalizedPath, normalizedPath)
    }
  }

  // Step 2: Handle write-only paths (paths that are writable but not explicitly in allowRead)
  // These paths need to be bound if they exist
  if (writeConfig?.allowOnly) {
    // Expand globs in allowWrite paths
    const expandedAllowWrite = await expandGlobPatterns(
      writeConfig.allowOnly,
      ripgrepConfig,
      mandatoryDenySearchDepth,
      abortSignal,
    )

    for (const pathPattern of expandedAllowWrite) {
      const normalizedPath = normalizePathForSandbox(pathPattern)

      // Skip if already handled in allowRead
      if (
        expandedAllowRead.some(
          readPath => normalizePathForSandbox(readPath) === normalizedPath,
        )
      ) {
        continue
      }

      if (!fs.existsSync(normalizedPath)) {
        logForDebugging(
          `[Sandbox Linux] Skipping non-existent write path: ${normalizedPath}`,
        )
        continue
      }

      args.push('--bind', normalizedPath, normalizedPath)
    }
  }

  // Step 2.5: Apply write protections within allowed write paths
  // This handles writeConfig.denyWithinAllow - files that should be read-only even within writable directories
  if (writeConfig?.denyWithinAllow || writeConfig?.allowOnly) {
    // Collect all paths that should be denied for writes (user-specified + mandatory)
    const denyPathsForWritePatterns = [
      ...(writeConfig.denyWithinAllow || []),
      ...(await linuxGetMandatoryDenyPaths(
        ripgrepConfig,
        mandatoryDenySearchDepth,
        abortSignal,
      )),
    ]

    // Expand globs in denyWithinAllow paths
    const expandedDenyWrite = await expandGlobPatterns(
      denyPathsForWritePatterns,
      ripgrepConfig,
      mandatoryDenySearchDepth,
      abortSignal,
    )

    // Build list of allowed write paths for checking (use expanded versions)
    const allowedWritePaths = writeConfig?.allowOnly
      ? await expandGlobPatterns(
          writeConfig.allowOnly,
          ripgrepConfig,
          mandatoryDenySearchDepth,
          abortSignal,
        ).then(paths => paths.map(normalizePathForSandbox))
      : []

    for (const pathPattern of expandedDenyWrite) {
      const normalizedPath = normalizePathForSandbox(pathPattern)

      // Skip /dev/* paths since --dev /dev already handles them
      if (normalizedPath.startsWith('/dev/')) {
        continue
      }

      // For non-existent paths, we need to check if they're within an allowed write path
      // If so, we should still protect them by binding a placeholder
      const isWithinAllowedPath = allowedWritePaths.some(
        allowedPath =>
          normalizedPath.startsWith(allowedPath + '/') ||
          normalizedPath === allowedPath,
      )

      if (!isWithinAllowedPath) {
        logForDebugging(
          `[Sandbox Linux] Skipping write-deny path not within allowed write paths: ${normalizedPath}`,
        )
        continue
      }

      if (fs.existsSync(normalizedPath)) {
        args.push('--ro-bind', normalizedPath, normalizedPath)
        logForDebugging(
          `[Sandbox Linux] Applied read-only bind for write-deny path: ${normalizedPath}`,
        )
      }
    }
  }

  // Step 3: Hide sensitive paths within allowed paths (denyWithinAllow, e.g., .env files)
  // Expand globs in denyWithinAllow for read restrictions
  const expandedDenyWithinAllow = await expandGlobPatterns(
    denyWithinAllow,
    ripgrepConfig,
    mandatoryDenySearchDepth,
    abortSignal,
  )

  for (const pathPattern of expandedDenyWithinAllow) {
    const normalizedPath = normalizePathForSandbox(pathPattern)

    if (!fs.existsSync(normalizedPath)) {
      logForDebugging(
        `[Sandbox Linux] Skipping non-existent deny-within-allow path: ${normalizedPath}`,
      )
      continue
    }

    const stat = fs.statSync(normalizedPath)
    if (stat.isDirectory()) {
      args.push('--tmpfs', normalizedPath)
    } else {
      args.push('--ro-bind', '/dev/null', normalizedPath)
    }
  }

  return args
}

/**
 * Generate filesystem bind mount arguments for bwrap
 * Dispatches to deny-only or allow-only implementation based on read config mode
 */
async function generateFilesystemArgs(
  readConfig: FsReadRestrictionConfig | undefined,
  writeConfig: FsWriteRestrictionConfig | undefined,
  tmpDir: string | undefined,
  seccompFilterPath?: string,
  ripgrepConfig: { command: string; args?: string[] } = { command: 'rg' },
  mandatoryDenySearchDepth: number = DEFAULT_MANDATORY_DENY_SEARCH_DEPTH,
  abortSignal?: AbortSignal,
): Promise<string[]> {
  // Merge tmpDir into writeConfig if present
  // This ensures tmpDir is automatically added to allowed write paths
  let mergedWriteConfig = writeConfig
  if (tmpDir && writeConfig) {
    const allowOnly = writeConfig.allowOnly || []
    if (!allowOnly.includes(tmpDir)) {
      mergedWriteConfig = {
        ...writeConfig,
        allowOnly: [...allowOnly, tmpDir],
      }
      logForDebugging(
        `[Sandbox Linux] Automatically added tmpDir to allowed write paths: ${tmpDir}`,
      )
    }
  }

  // Dispatch to appropriate implementation based on read config mode
  if (readConfig?.mode === 'deny-only') {
    // Use deny-only implementation (original logic)
    return generateDenyOnlyFilesystemArgs(
      readConfig.denyPaths,
      mergedWriteConfig,
      ripgrepConfig,
      mandatoryDenySearchDepth,
      abortSignal,
    )
  } else if (readConfig?.mode === 'allow-only') {
    // Use allow-only implementation (new logic)
    return generateAllowOnlyFilesystemArgs(
      readConfig.allowPaths,
      readConfig.denyWithinAllow,
      mergedWriteConfig,
      seccompFilterPath,
      ripgrepConfig,
      mandatoryDenySearchDepth,
      abortSignal,
    )
  } else {
    // No read restrictions: mount entire / (respecting write restrictions if any)
    const args: string[] = []
    if (mergedWriteConfig) {
      // Has write restrictions: mount / as read-only, then bind writable paths
      args.push('--ro-bind', '/', '/')

      for (const pathPattern of mergedWriteConfig.allowOnly || []) {
        const normalizedPath = normalizePathForSandbox(pathPattern)

        // Skip /dev/* paths since --dev /dev already handles them
        if (normalizedPath.startsWith('/dev/')) {
          continue
        }

        if (!fs.existsSync(normalizedPath)) {
          logForDebugging(
            `[Sandbox Linux] Skipping non-existent write path: ${normalizedPath}`,
          )
          continue
        }

        args.push('--bind', normalizedPath, normalizedPath)
      }

      logForDebugging(
        `[Sandbox Linux] No read restrictions, write restrictions applied`,
      )
    } else {
      // No restrictions: mount / as read-write
      args.push('--bind', '/', '/')
      logForDebugging(`[Sandbox Linux] No read or write restrictions`)
    }
    return args
  }
}

/**
 * Wrap a command with sandbox restrictions on Linux
 *
 * UNIX SOCKET BLOCKING (APPLY-SECCOMP):
 * This implementation uses a custom apply-seccomp binary to block Unix domain socket
 * creation for user commands while allowing network infrastructure:
 *
 * Stage 1: Outer bwrap - Network and filesystem isolation (NO seccomp)
 *   - Bubblewrap starts with isolated network namespace (--unshare-net)
 *   - Bubblewrap applies PID namespace isolation (--unshare-pid and --proc)
 *   - Filesystem restrictions are applied (read-only mounts, bind mounts, etc.)
 *   - Socat processes start and connect to Unix socket bridges (can use socket(AF_UNIX, ...))
 *
 * Stage 2: apply-seccomp - Seccomp filter application (ONLY seccomp)
 *   - apply-seccomp binary applies seccomp filter via prctl(PR_SET_SECCOMP)
 *   - Sets PR_SET_NO_NEW_PRIVS to allow seccomp without root
 *   - Execs user command with seccomp active (cannot create new Unix sockets)
 *
 * This solves the conflict between:
 * - Security: Blocking arbitrary Unix socket creation in user commands
 * - Functionality: Network sandboxing requires socat to call socket(AF_UNIX, ...) for bridge connections
 *
 * The seccomp-bpf filter blocks socket(AF_UNIX, ...) syscalls, preventing:
 * - Creating new Unix domain socket file descriptors
 *
 * Security limitations:
 * - Does NOT block operations (bind, connect, sendto, etc.) on inherited Unix socket FDs
 * - Does NOT prevent passing Unix socket FDs via SCM_RIGHTS
 * - For most sandboxing use cases, blocking socket creation is sufficient
 *
 * The filter allows:
 * - All TCP/UDP sockets (AF_INET, AF_INET6) for normal network operations
 * - All other syscalls
 *
 * PLATFORM NOTE:
 * The allowUnixSockets configuration is not path-based on Linux (unlike macOS)
 * because seccomp-bpf cannot inspect user-space memory to read socket paths.
 *
 * Requirements for seccomp filtering:
 * - Pre-built apply-seccomp binaries are included for x64 and ARM64
 * - Pre-generated BPF filters are included for x64 and ARM64
 * - Other architectures are not currently supported (no apply-seccomp binary available)
 * - To use sandboxing without Unix socket blocking on unsupported architectures,
 *   set allowAllUnixSockets: true in your configuration
 * Dependencies are checked by hasLinuxSandboxDependenciesSync() before enabling the sandbox.
 */
export async function wrapCommandWithSandboxLinux(
  params: LinuxSandboxParams,
): Promise<string> {
  const {
    command,
    needsNetworkRestriction,
    httpSocketPath,
    socksSocketPath,
    httpProxyPort,
    socksProxyPort,
    readConfig,
    writeConfig,
    enableWeakerNestedSandbox,
    allowAllUnixSockets,
    binShell,
    ripgrepConfig = { command: 'rg' },
    mandatoryDenySearchDepth = DEFAULT_MANDATORY_DENY_SEARCH_DEPTH,
    abortSignal,
  } = params

  // Determine if we have restrictions to apply
  // Read: dual mode - check based on mode type
  // Write: allowOnly pattern - undefined means no restrictions, any config means restrictions
  const hasReadRestrictions =
    readConfig &&
    ((readConfig.mode === 'deny-only' && readConfig.denyPaths.length > 0) ||
      readConfig.mode === 'allow-only')
  const hasWriteRestrictions = writeConfig !== undefined

  // Check if we need any sandboxing
  if (
    !needsNetworkRestriction &&
    !hasReadRestrictions &&
    !hasWriteRestrictions
  ) {
    return command
  }

  // Determine the final tmpDir value upfront and ensure it exists
  // This ensures both generateProxyEnvVars and generateFilesystemArgs use the same value
  const tmpDir = ensureTmpDir(params.tmpDir, 'Sandbox Linux')

  const bwrapArgs: string[] = []
  let seccompFilterPath: string | undefined = undefined

  try {
    // ========== SECCOMP FILTER (Unix Socket Blocking) ==========
    // Use bwrap's --seccomp flag to apply BPF filter that blocks Unix socket creation
    //
    // NOTE: Seccomp filtering is only enabled when allowAllUnixSockets is false
    // (when true, Unix sockets are allowed)
    if (!allowAllUnixSockets) {
      seccompFilterPath = generateSeccompFilter() ?? undefined
      if (!seccompFilterPath) {
        // Seccomp not available - log warning and continue without it
        // This provides graceful degradation on systems without seccomp binaries
        logForDebugging(
          '[Sandbox Linux] Seccomp filter not available (missing binaries). ' +
            'Continuing without Unix socket blocking - sandbox will still provide ' +
            'filesystem and network isolation but Unix sockets will be allowed.',
          { level: 'warn' },
        )
      } else {
        // Track filter for cleanup and register exit handler
        // Only track runtime-generated filters (not pre-generated ones from vendor/)
        if (!seccompFilterPath.includes('/vendor/seccomp/')) {
          generatedSeccompFilters.add(seccompFilterPath)
          registerSeccompCleanupHandler()
        }

        logForDebugging(
          '[Sandbox Linux] Generated seccomp BPF filter for Unix socket blocking',
        )
      }
    } else if (allowAllUnixSockets) {
      logForDebugging(
        '[Sandbox Linux] Skipping seccomp filter - allowAllUnixSockets is enabled',
      )
    }

    // ========== NETWORK RESTRICTIONS ==========
    if (needsNetworkRestriction) {
      // Always unshare network namespace to isolate network access
      // This removes all network interfaces, effectively blocking all network
      bwrapArgs.push('--unshare-net')

      // If proxy sockets are provided, bind them into the sandbox to allow
      // filtered network access through the proxy. If not provided, network
      // is completely blocked (empty allowedDomains = block all)
      if (httpSocketPath && socksSocketPath) {
        // Verify socket files still exist before trying to bind them
        if (!fs.existsSync(httpSocketPath)) {
          throw new Error(
            `Linux HTTP bridge socket does not exist: ${httpSocketPath}. ` +
              'The bridge process may have died. Try reinitializing the sandbox.',
          )
        }
        if (!fs.existsSync(socksSocketPath)) {
          throw new Error(
            `Linux SOCKS bridge socket does not exist: ${socksSocketPath}. ` +
              'The bridge process may have died. Try reinitializing the sandbox.',
          )
        }

        // Bind both sockets into the sandbox
        bwrapArgs.push('--bind', httpSocketPath, httpSocketPath)
        bwrapArgs.push('--bind', socksSocketPath, socksSocketPath)

        // Add proxy environment variables
        // HTTP_PROXY points to the socat listener inside the sandbox (port 3128)
        // which forwards to the Unix socket that bridges to the host's proxy server
        const proxyEnv = generateProxyEnvVars(
          3128, // Internal HTTP listener port
          1080, // Internal SOCKS listener port
          {
            tmpDir: tmpDir,
            noProxyAddresses: params.noProxyAddresses,
          },
        )
        bwrapArgs.push(
          ...proxyEnv.flatMap((env: string) => {
            const firstEq = env.indexOf('=')
            const key = env.slice(0, firstEq)
            const value = env.slice(firstEq + 1)
            return ['--setenv', key, value]
          }),
        )

        // Add host proxy port environment variables for debugging/transparency
        // These show which host ports the Unix socket bridges connect to
        if (httpProxyPort !== undefined) {
          bwrapArgs.push(
            '--setenv',
            'CLAUDE_CODE_HOST_HTTP_PROXY_PORT',
            String(httpProxyPort),
          )
        }
        if (socksProxyPort !== undefined) {
          bwrapArgs.push(
            '--setenv',
            'CLAUDE_CODE_HOST_SOCKS_PROXY_PORT',
            String(socksProxyPort),
          )
        }
      }
      // If no sockets provided, network is completely blocked (--unshare-net without proxy)
    }

    // ========== CUSTOM ENVIRONMENT VARIABLES ==========
    if (params.envVars && params.envVars.length > 0) {
      for (const { name, value } of params.envVars) {
        if (RESERVED_ENV_VARS.has(name.toUpperCase())) {
          logForDebugging(
            `[Sandbox Linux] Skipping reserved environment variable: ${name}`,
            { level: 'warn' },
          )
          continue
        }
        bwrapArgs.push('--setenv', name, value)
      }
      const addedCount = params.envVars.filter(
        v => !RESERVED_ENV_VARS.has(v.name.toUpperCase()),
      ).length
      if (addedCount > 0) {
        logForDebugging(
          `[Sandbox Linux] Added ${addedCount} custom environment variable(s)`,
        )
      }
    }

    // ========== FILESYSTEM RESTRICTIONS ==========
    const fsArgs = await generateFilesystemArgs(
      readConfig,
      writeConfig,
      tmpDir,
      seccompFilterPath,
      ripgrepConfig,
      mandatoryDenySearchDepth,
      abortSignal,
    )
    bwrapArgs.push(...fsArgs)

    // Always bind /dev
    bwrapArgs.push('--dev', '/dev')

    // ========== PID NAMESPACE ISOLATION ==========
    // IMPORTANT: These must come AFTER filesystem binds for nested bwrap to work
    // By default, always unshare PID namespace and mount fresh /proc.
    // If we don't have --unshare-pid, it is possible to escape the sandbox.
    // If we don't have --proc, it is possible to read host /proc and leak information about code running
    // outside the sandbox. But, --proc is not available when running in unprivileged docker containers
    // so we support running without it if explicitly requested.
    bwrapArgs.push('--unshare-pid')
    if (!enableWeakerNestedSandbox) {
      // Mount fresh /proc if PID namespace is isolated (secure mode)
      bwrapArgs.push('--proc', '/proc')
    }

    // ========== COMMAND ==========
    // Use the user's shell (zsh, bash, etc.) to ensure aliases/snapshots work
    // Resolve the full path to the shell binary since bwrap doesn't use $PATH
    const shellName = binShell || 'bash'
    const shellPathResult = spawnSync('which', [shellName], {
      encoding: 'utf8',
    })
    if (shellPathResult.status !== 0) {
      throw new Error(`Shell '${shellName}' not found in PATH`)
    }
    const shell = shellPathResult.stdout.trim()
    bwrapArgs.push('--', shell, '-c')

    // If we have network restrictions, use the network bridge setup with apply-seccomp for seccomp
    // Otherwise, just run the command directly with apply-seccomp if needed
    if (needsNetworkRestriction && httpSocketPath && socksSocketPath) {
      // Pass seccomp filter to buildSandboxCommand for apply-seccomp application
      // This allows socat to start before seccomp is applied
      const sandboxCommand = buildSandboxCommand(
        httpSocketPath,
        socksSocketPath,
        command,
        seccompFilterPath,
        shell,
      )
      bwrapArgs.push(sandboxCommand)
    } else if (seccompFilterPath) {
      // No network restrictions but we have seccomp - use apply-seccomp directly
      // apply-seccomp is a simple C program that applies the seccomp filter and execs the command
      const applySeccompBinary = getApplySeccompBinaryPath()
      if (!applySeccompBinary) {
        throw new Error(
          'apply-seccomp binary not found. This should have been caught earlier. ' +
            'Ensure vendor/seccomp/{x64,arm64}/apply-seccomp binaries are included in the package.',
        )
      }

      const applySeccompCmd = shellquote.quote([
        applySeccompBinary,
        seccompFilterPath,
        shell,
        '-c',
        command,
      ])
      bwrapArgs.push(applySeccompCmd)
    } else {
      bwrapArgs.push(command)
    }

    // Build the outer bwrap command
    const wrappedCommand = shellquote.quote(['bwrap', ...bwrapArgs])

    const restrictions = []
    if (needsNetworkRestriction) restrictions.push('network')
    if (hasReadRestrictions || hasWriteRestrictions)
      restrictions.push('filesystem')
    if (seccompFilterPath) restrictions.push('seccomp(unix-block)')

    logForDebugging(
      `[Sandbox Linux] Wrapped command with bwrap (${restrictions.join(', ')} restrictions)`,
    )

    logForDebugging(`[Sandbox Linux] Final wrapped command: ${wrappedCommand}`)

    return wrappedCommand
  } catch (error) {
    // Clean up seccomp filter on error
    if (seccompFilterPath && !seccompFilterPath.includes('/vendor/seccomp/')) {
      generatedSeccompFilters.delete(seccompFilterPath)
      try {
        cleanupSeccompFilter(seccompFilterPath)
      } catch (cleanupError) {
        logForDebugging(
          `[Sandbox Linux] Failed to clean up seccomp filter on error: ${cleanupError}`,
          { level: 'error' },
        )
      }
    }
    // Re-throw the original error
    throw error
  }
}
